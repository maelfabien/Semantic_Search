{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out what sentences are similar to your test sentence\n",
    "How similar is \"Can I reset the cat\" to a sentence in our quora dataset?\n",
    "Just run the notebook and it will return similar sentences for a test sentence.\n",
    "Then simply add your own in the **Enter you own test sentence** cell and then re-run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the USE module\n",
    "Althought we have created the embeddings for our test dataset already we still need to download the USE module to encode the new test sentences<br>\n",
    "The first time you run this the USE module will be downloaded but after that it will be cached.<br>\n",
    "As a result the first time you run this it might take a few seconds to download the module but after that it \n",
    "will run much faster. <br>\n",
    "For more info on this see https://www.tensorflow.org/hub/basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an interactive TF session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the saved embeddings\n",
    "Get the embeddings which are saved in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./embeddings.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>[-0.043053239583969116, 0.05912359803915024, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>[0.04468201845884323, 0.0032161467242985964, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>[0.031296346336603165, -0.002411748981103301, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>[0.0734066367149353, 0.055123668164014816, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>[0.05466366186738014, -0.003594229696318507, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "1                     How can I be a good geologist?   \n",
       "2        How do I read and find my YouTube comments?   \n",
       "3               What can make Physics easy to learn?   \n",
       "4        What was your first sexual experience like?   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.043053239583969116, 0.05912359803915024, -...  \n",
       "1  [0.04468201845884323, 0.0032161467242985964, 0...  \n",
       "2  [0.031296346336603165, -0.002411748981103301, ...  \n",
       "3  [0.0734066367149353, 0.055123668164014816, 0.0...  \n",
       "4  [0.05466366186738014, -0.003594229696318507, -...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the similarity score for our test sentence and the saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "sts_encode2 = tf.placeholder(tf.float32)\n",
    "\n",
    "# For evaluation we use exactly normalized rather than\n",
    "# approximately normalized.\n",
    "sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\n",
    "\n",
    "cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "clip_cosine_similarities = tf.clip_by_value(cosine_similarities, 0.0, 1.0)\n",
    "sim_scores = 1.0 - tf.divide(tf.acos(clip_cosine_similarities), 3.14)\n",
    "\n",
    "def get_scores(session, text_a, text_b):\n",
    "    \"\"\"Returns the similarity scores\"\"\"\n",
    "    scores= session.run(\n",
    "        [sim_scores],\n",
    "        feed_dict={\n",
    "            sts_input1: text_a,\n",
    "            sts_encode2: text_b\n",
    "        })\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the similarity of the sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(sessions, sentence, num):\n",
    "    examples = [e for e in df['embeddings']]\n",
    "    scores = get_scores(session, [sentence], examples)\n",
    "    df['cosine'] = scores[0].tolist()\n",
    "    return(df.sort_values('cosine', ascending=False).head(n=num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the result in a nice format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(test, num=20):\n",
    "    res = get_results(session, test, num).round(4)\n",
    "    res = (res.set_index('cosine')).drop(columns=['embeddings'])\n",
    "    print('{}\\n'.format(test))\n",
    "    print('\\x1b[31mScore{:<1} \\x1b[0m: \\x1b[34m Matching sentence\\x1b[0m'.format(''))\n",
    "\n",
    "    for i in res.iterrows():\n",
    "        print('\\x1b[31m{:<6} \\x1b[0m: \\x1b[0m \\x1b[34m{}\\x1b[0m'.format(i[0], i[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your own test sentece\n",
    "Open the test dataset and look at some of the sentences. <br>\n",
    "Then try and enter your own sentences and see if the matches make sences. <br>\n",
    "What about mis-spelling? Ordering? Using different words with similar meaning? <br>\n",
    "How do these impact the cosine similarity score? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is purpose?\n",
      "\n",
      "\u001b[31mScore  \u001b[0m: \u001b[34m Matching sentence\u001b[0m\n",
      "\u001b[31m0.8483 \u001b[0m: \u001b[0m \u001b[34mWhat is purpose of life?\u001b[0m\n",
      "\u001b[31m0.8197 \u001b[0m: \u001b[0m \u001b[34mWhat is the meaning and purpose to life?\u001b[0m\n",
      "\u001b[31m0.8129 \u001b[0m: \u001b[0m \u001b[34mWhat's the purpose of life? What is life actually about?\u001b[0m\n",
      "\u001b[31m0.7922 \u001b[0m: \u001b[0m \u001b[34mWhat do you feel is the purpose of life?\u001b[0m\n",
      "\u001b[31m0.7912 \u001b[0m: \u001b[0m \u001b[34mWhat the meaning of this all life?\u001b[0m\n",
      "\u001b[31m0.7879 \u001b[0m: \u001b[0m \u001b[34mWhat is the meaning of life? Whats our purpose on Earth?\u001b[0m\n",
      "\u001b[31m0.7865 \u001b[0m: \u001b[0m \u001b[34mWhat's are the meaning of life?\u001b[0m\n",
      "\u001b[31m0.762  \u001b[0m: \u001b[0m \u001b[34mWhat is the exact meaning of life?\u001b[0m\n",
      "\u001b[31m0.7548 \u001b[0m: \u001b[0m \u001b[34mDo we truly have any purpose in life? Or do we create a purpose to make ourselves feel significant in the very vast world, or to make ourselves feel that our existence in the vast world is required?\u001b[0m\n",
      "\u001b[31m0.742  \u001b[0m: \u001b[0m \u001b[34mWhy is creativity important?\u001b[0m\n",
      "\u001b[31m0.7267 \u001b[0m: \u001b[0m \u001b[34mWhat is the essence of enlightenment?\u001b[0m\n",
      "\u001b[31m0.7246 \u001b[0m: \u001b[0m \u001b[34mWhat is the meaning of the future?\u001b[0m\n",
      "\u001b[31m0.7243 \u001b[0m: \u001b[0m \u001b[34mWhy should I live?\u001b[0m\n",
      "\u001b[31m0.7232 \u001b[0m: \u001b[0m \u001b[34mWhy do people collect things?\u001b[0m\n",
      "\u001b[31m0.7173 \u001b[0m: \u001b[0m \u001b[34mWhat is enlightenment?\u001b[0m\n",
      "\u001b[31m0.7149 \u001b[0m: \u001b[0m \u001b[34mWhat is the aim of science?\u001b[0m\n",
      "\u001b[31m0.7145 \u001b[0m: \u001b[0m \u001b[34mWhat makes understanding death philosophical?\u001b[0m\n",
      "\u001b[31m0.707  \u001b[0m: \u001b[0m \u001b[34mWhy does understanding death philosophical?\u001b[0m\n",
      "\u001b[31m0.7045 \u001b[0m: \u001b[0m \u001b[34mWhich psychological need does 'collecting' fulfill?\u001b[0m\n",
      "\u001b[31m0.7015 \u001b[0m: \u001b[0m \u001b[34mWhat does the phrase \"love begets love\" mean?\u001b[0m\n",
      "\u001b[31m0.7    \u001b[0m: \u001b[0m \u001b[34mWhat are the most important things for living a good life?\u001b[0m\n",
      "\u001b[31m0.6943 \u001b[0m: \u001b[0m \u001b[34mWhat's beyond our Universe?\u001b[0m\n",
      "\u001b[31m0.6913 \u001b[0m: \u001b[0m \u001b[34mWhat is a \"function\" in the context of functional programming?\u001b[0m\n",
      "\u001b[31m0.69   \u001b[0m: \u001b[0m \u001b[34mWhat exactly is a framework, in layman's terms?\u001b[0m\n",
      "\u001b[31m0.6861 \u001b[0m: \u001b[0m \u001b[34mWhat is functional programming?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simply use print_res(\"what is purpose?\") to return the top 20 best matches\n",
    "Or use print_res(\"what is purpose?\", 100) to choose how many best matches to return\n",
    "\"\"\"\n",
    "print_res(\"what is purpose?\", 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need some inspiration? \n",
    "Generate some random sentences from the Quora dataset and see if you can alter them and stil get a high similarity score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: Have you ever been fired?\n",
      " 2: Why do we get sea breezes in summer but rarely in winter?\n",
      " 3: How will the implementation of GST bill impact the lives of common people?\n",
      " 4: Is my boyfriend lying about his true feelings for his friend and is he secretly attracted to her?\n",
      " 5: You have given all statement as correct in UNCCD question in CSE prelim 2016. While many coachings have taken 2nd statement as wrong.?\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(df.sample(n=5).iterrows()):\n",
    "    print('{:2}: {}'.format(i+1, s[1][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
